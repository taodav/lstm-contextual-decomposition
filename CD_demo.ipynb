{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchtext import data, datasets\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as O\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from model import LSTMSentiment\n",
    "from argparse import ArgumentParser\n",
    "from data_utils import load_sst, makedirs, get_args\n",
    "from train import get_accuracy, train_model\n",
    "from logit import load_sst_logistic_reg, logit_clf\n",
    "from CD import CD, get_batches\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()\n",
    "torch.cuda.set_device(0)\n",
    "inputs, outputs, train_iter, valid_iter, train_sst, valid_sst = load_sst(args)\n",
    "args[\"n_embed\"] = len(inputs.vocab)\n",
    "args[\"d_out\"] = len(outputs.vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\cuda\\__init__.py:116: UserWarning: \n",
      "    Found GPU0 GeForce GTX 960M which is of cuda capability 5.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(\"results/best_snapshot.pt\"):\n",
    "    model = LSTMSentiment(args)\n",
    "    model.cuda()\n",
    "    model = model.load_state_dict(torch.load(\"results/best_snapshot.pt\"))\n",
    "else:\n",
    "    model = train_model(train_iter, valid_iter, valid_sst, inputs, outputs, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = load_sst_logistic_reg(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.82      0.80      0.81       428\n",
      "   negative       0.81      0.83      0.82       444\n",
      "\n",
      "avg / total       0.82      0.82      0.82       872\n",
      "\n",
      "0.8188073394495413\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer= lambda doc:doc, lowercase=False)\n",
    "\n",
    "training_data = [text for text in train.text]\n",
    "training_labels = [label for label in train.label]\n",
    "validation_data = [text for text in valid.text]\n",
    "validation_labels = [label for label in valid.label]\n",
    "test_data = [text for text in test.text]\n",
    "test_labels = [label for label in test.label]\n",
    "\n",
    "\n",
    "bag_of_words = vectorizer.fit_transform(training_data)\n",
    "\n",
    "\n",
    "clf = LogisticRegression(dual=True)\n",
    "clf.fit(bag_of_words, training_labels)\n",
    "predictions = clf.predict(vectorizer.transform(validation_data))\n",
    "\n",
    "print(metrics.classification_report(validation_labels, predictions,target_names=[\"positive\",\"negative\"]))\n",
    "print(metrics.accuracy_score(validation_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_vectorizer = CountVectorizer(tokenizer = lambda doc:doc, lowercase=False)\n",
    "validation_vectorizer.fit_transform(validation_data)\n",
    "word_coef_lookup = {feature: coef for coef, feature in zip(clf.coef_[0], vectorizer.get_feature_names())}\n",
    "word_validation_coef_lookup = {word:word_coef_lookup[word] for word in validation_vectorizer.vocabulary_ if word in word_coef_lookup}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting batches...\n"
     ]
    }
   ],
   "source": [
    "args[\"batch_size\"] = 1\n",
    "inputs, outputs, train_iter, valid_iter, train_sst, valid_sst = load_sst(args)\n",
    "\n",
    "batch_nums = list(range(len(train_iter)))\n",
    "data = get_batches(batch_nums, train_iter, valid_iter, dset='train') \n",
    "cd = CD(model, inputs, clf, data, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_ones = [60, 15, 16]\n",
    "num = 12\n",
    "print(\"Review level CD scores\")\n",
    "res_review = cd.CD_phrase(cd.dissenting[num])\n",
    "print()\n",
    "print(\"Word level CD scores\")\n",
    "res_by_word = cd.CD_word(cd.dissenting[num])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = {}\n",
    "if os.path.isfile(\"CD_SCORE_individual.csv\"):\n",
    "    df = pd.read_csv(\"CD_SCORE_individual.csv\", index_col=0)\n",
    "    words = {row[\"word\"]:row[\"score\"] for index, row in df.iterrows()} \n",
    "else:\n",
    "    #Array of phrases\n",
    "    for ind in range(len(data)):\n",
    "        if ind%50 ==0:\n",
    "            print(\"ind\", ind)\n",
    "        text = data[ind].text.data[:, 0]\n",
    "        vect2Word = [inputs.vocab.itos[i] for i in text]\n",
    "    #     print (vect2Word)\n",
    "        for i in range(len(vect2Word)):\n",
    "            if(vect2Word[i] not in words):\n",
    "                words[vect2Word[i]] = cd.context_decomp(data[ind], i, i)\n",
    "    df = pd.DataFrame(list(words.items()), columns=[\"word\", \"score\"])\n",
    "    df.to_csv(\"CD_SCORE_individual.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "\n",
    "for key, val  in word_validation_coef_lookup.items():\n",
    "    if key in words:\n",
    "        x.append(word_validation_coef_lookup[key])\n",
    "        y.append(words[key])\n",
    "    \n",
    "print(sp.stats.pearsonr(x,y))\n",
    "# y_10 = [y * 10 for elem in y]\n",
    "plt.plot(x , y, 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tree import Tree\n",
    "\n",
    "ROOT = 'ROOT'\n",
    "\n",
    "negation_terms = set(['not', 'nâ€™t', 'lacks', 'nobody', 'nor', 'nothing', 'neither', 'never', 'none', 'nowhere', 'remotely'])\n",
    "parents_set = list()\n",
    "\n",
    "trees = []\n",
    "with open(os.path.expanduser('./.data/sst/trees/train.txt')) as f:\n",
    "    for line in f:\n",
    "        tree = Tree.fromstring(line)\n",
    "        trees.append(tree)\n",
    "\n",
    "def getNegatingSubphrases(parent, review_id, review, parent_index, tree_height):\n",
    "    nodes = [{\"node\":node} for node in parent]\n",
    "    start_index = parent_index\n",
    "  \n",
    "  # Get the start and end indexes for each child based off of their parent's index. \n",
    "    for node in nodes:\n",
    "        if type(node['node']) is nltk.Tree:\n",
    "            end_index = len(node[\"node\"].leaves()) + start_index\n",
    "            node['start_index'] = start_index\n",
    "            node['end_index'] = end_index\n",
    "            start_index = end_index\n",
    "      \n",
    "    if len(parent.leaves()) > 10:\n",
    "        if len(nodes) >= 2:\n",
    "            first_child = nodes[0]['node']\n",
    "            second_child = nodes[1]['node']\n",
    "\n",
    "            first_child_first_two_words = set(list(first_child.leaves())[:2])\n",
    "            # if the first child has some negation terms\n",
    "            if first_child_first_two_words.intersection(negation_terms):\n",
    "                if int(second_child.label()) in [0,1,3,4]:\n",
    "                    parents_set.append({\"review_id\":review_id,\"review\":review, \n",
    "                                      \"parent\":parent, \n",
    "                                      \"first_child\": first_child, \n",
    "                                      \"second_child\":second_child, \n",
    "                                      \"first_child_start_index\":nodes[0]['start_index'],\n",
    "                                      \"first_child_end_index\":nodes[0]['end_index'],\n",
    "                                      \"second_child_start_index\": nodes[1]['start_index'],\n",
    "                                      \"second_child_end_index\": nodes[1]['end_index'],\n",
    "                                      \"height\":tree_height\n",
    "                                     })\n",
    "\n",
    "  # keep on recursing \n",
    "    for node in nodes:\n",
    "        if type(node['node']) is nltk.Tree:\n",
    "            getNegatingSubphrases(node['node'], review_id, review, node['start_index'], tree_height + 1)\n",
    "\n",
    "for i, tree in enumerate(trees):\n",
    "    getNegatingSubphrases(tree, i, tree, 0,0)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_labels = set([0,1])\n",
    "positive_labels = set([3,4])\n",
    "\n",
    "dissenting_subphrase_reviews = []\n",
    "def getDissentingSubphrase(parent, review_label, review_length, review, review_id,parent_index, tree_height):\n",
    "    continue_recursion = True\n",
    "\n",
    "    nodes = [{\"node\":node} for node in parent]\n",
    "    start_index = parent_index\n",
    "\n",
    "    # Get the start and end indexes for each child based off of their parent's index. \n",
    "    for node in nodes:\n",
    "        if type(node['node']) is nltk.Tree:\n",
    "            end_index = len(node[\"node\"].leaves()) + start_index\n",
    "            node['start_index'] = start_index\n",
    "            node['end_index'] = end_index\n",
    "            start_index = end_index\n",
    "  \n",
    "    for node in nodes:\n",
    "        if type(node['node']) is nltk.Tree:\n",
    "            node_label = int(node['node'].label())\n",
    "            node_length = len(node['node'].leaves())\n",
    "            if ((review_label in negative_labels and node_label in positive_labels) or (review_label in positive_labels and node_label in negative_labels)):\n",
    "                if (review_length / float(3)) < node_length and (review_length * 2.0 / float(3)) > node_length:\n",
    "                    dissenting_subphrase_reviews.append({\"review_id\":review_id,\n",
    "                                                       \"review\":review, \n",
    "                                                       \"parent\":parent,\n",
    "                                                       \"child_start_index\":node['start_index'],\n",
    "                                                       \"child_end_index\":node['end_index'],\n",
    "                                                       \"dissenting_subphrase\": node['node'],\n",
    "                                                       \"height\":tree_height})\n",
    "   \n",
    "    for node in nodes:\n",
    "        if type(node['node']) is nltk.Tree:\n",
    "            getDissentingSubphrase(node['node'], review_label, review_length, review, review_id, node['start_index'], tree_height+1)\n",
    "\n",
    "for i,tree in enumerate(trees):\n",
    "    getDissentingSubphrase(tree, int(tree.label()), len(tree.leaves()), tree, i, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_lookup = {}\n",
    "#Array of phrases\n",
    "for ind in range(len(data)):\n",
    "    text = data[ind].text.data[:, 0]\n",
    "    vect2Word = tuple(inputs.vocab.itos[i] for i in text)\n",
    "    review_lookup[vect2Word] = data[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dissenting_subphrase_cd_scores = []\n",
    "dissenting_subphrase_labels = [] \n",
    "for review in dissenting_subphrase_reviews:\n",
    "    review_vector = review_lookup[tuple(review['review'].leaves())]\n",
    "    dissenting_subphrase_cd_score = cd.context_decomp(review_vector, review['child_start_index'],review['child_end_index'])\n",
    "    subphrase_label = review['dissenting_subphrase'].label()\n",
    "    \n",
    "    dissenting_subphrase_cd_scores.append(dissenting_subphrase_cd_score)\n",
    "    dissenting_subphrase_labels.append(subphrase_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats, integrate\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "results = zip(dissenting_subphrase_cd_scores, dissenting_subphrase_labels)\n",
    "positive_subphrase_cd_scores = [score for score, label in results if int(label) in [3,4]]\n",
    "results = zip(dissenting_subphrase_cd_scores, dissenting_subphrase_labels)\n",
    "negative_subphrase_cd_scores = [score for score, label in results if int(label) in [0,1]]\n",
    "\n",
    "x = np.asarray(positive_subphrase_cd_scores)\n",
    "x2 = np.asarray(negative_subphrase_cd_scores)\n",
    "plt.xlim(-7, 7)\n",
    "sns.distplot(x,hist=False, rug=True, label=\"Positive Sentiment\")\n",
    "sns.distplot(x2,hist=False, rug=True, label=\"Negative Sentiment\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = dissenting_subphrase_reviews[2]\n",
    "data_batch = review_lookup[tuple(review[\"review\"].leaves())]\n",
    "cd.CD_subphrases(data_batch, review['child_start_index'],review['child_end_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
